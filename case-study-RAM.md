#Case-study оптимизации RAM
Актуальная проблема
После первой оптимизации CPU. Удалось агреггировать данные файла с 100 000 строк за менее 30 секунд.
Но была выявленна следующая проблема. Программа потребялем много оперативной памяти. При файле со 100 000 строк данных затрачивается 1292 Mb RAM.
Я решил исправить эту проблему, оптимизировав эту программу.

###Цель
Потребление ОЗУ менее 75Mb при 100 000 строк данных.

###Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я буду вычислять потребление оперативной памяти на тестовом файле в 500 строк.
Для понимая того какая будет асимтотика я собрал общее кол-во потребляемого ОЗУ методов на разном кол-ве строк данных
 



| Кол-во строк  | Byte       | Kb        |    Mb  |
| ------------- |:----------:|:---------:|:------:|
|   **10**      |337856      |329,94     |0,32    |
|   **20**      |337856      |337,70     |0,33    |
|   **30**      |354632      |346,32     |0,34    |
|   **50**      |370176      |361,50     |0,35    |
|   **100**     |411640      |401,99     |0,39    |
|   **500**     |738888      |721,57     |0,70    |
|   **large**  |2564204832  |2504106,28  |2445,42 |
    
![diagram](https://raw.githubusercontent.com/VidgarVii/rails-optimization-2-task2/task-2-optimaiz-ram/benchmarks/RAM/diagram.jpg)

Гарантия корректности работы оптимизированной программы
Написан rspec тест.

###Feedback-Loop

* Профилирование данных по потребелению памяти.
  * Для сбора данных я собрал тестовый файл с данными в 500 строк. 
* Поиск точки роста
* Оптимизация проблемного кода
* Тестирование профилировщиками результата

Для того, чтобы найти "точки роста" для оптимизации я воспользовался инструментами:
- ruby-prof - Модуль Memory
- memory_profile

Вот какие проблемы удалось найти и решить

####Ваша находка №1
* Потребление памяти 720,7 Кб *ruby-prof*
![point](https://raw.githubusercontent.com/VidgarVii/rails-optimization-2-task2/task-2-optimaiz-ram/benchmarks/RAM/reports/img/point-1.png)
первая вызвана работай гема MultiJson. Там происходит сериализация данных из хеша в json

Сплит (при 505 вызовов) плодит множества алокаций из-за этого забивается память почти на 20%. 3432(ruby-prof) - 3922(memory_profile)
Уменьшить кол-во алокаций при сплите данных

Я вынес статичные данные в константы. Добавил коммент frozen_string_literal. Разбил метод сплит по условиям

После оптимизации* кода получилось уменьшить кол-во алокаций в общем коде с 15072 до 13595 (memory_profile). 
В методе сплит было не существеное изменение 3376(memory_profile) - 3432(ruby-prof)
Уменьшить кол-во вызовов сплит не удалось.

Общая потребление памяти програамы стала 655,125 Кб (- 65,5 Кб) ruby-prof

####Ваша находка №2

Я заметил что сплит формирует лишние данные, которые мне нужны. Я попробую от них избавиться. 

Спустя некоторых манипуляций...

**как изменился отчёт профилировщика**

В худшую сторону. Это был фэйл. Данные стали плодиться как хомяки в брачный период. Вернул всё обратно. 

**Попытка 2**

Обернул в цикл while сбор данных для сессий.

Получилось снизить общее потребление памяти до 598,91 Кб (ruby-prof)

Кол-во алокаций снизилось до 1068332 (memory_profile)

#####Точка роста.
По данным ruby-prof Split спустился на 3 позицию. 

memory_profile указывает, что львинная доля памяти уходит на сроки.
Кол-во массивов снизилось с 191640 до 174760
```
allocated memory by class
-----------------------------------
    631093  String
    174760  Array
    143904  File
     56920  Hash

```
  
####Ваша находка №3


Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными. Удалось улучшить метрику системы с того, что у вас было в начале, до того, что получилось в конце и уложиться в заданный бюджет.

Какими ещё результами можете поделиться

Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы о performance-тестах, которые вы написали